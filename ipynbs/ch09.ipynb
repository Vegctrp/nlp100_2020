{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch09.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aG4GHjAX_zYq",
        "colab_type": "text"
      },
      "source": [
        "# 第9章: RNN, CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqGJvDqECM4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5F4wlIzHDhV2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "91d55629-5009-4bb7-ace2-f831ad1cb844"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrsxn4_8Djp7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "d4721f50-f232-452c-d4e5-542c90570893"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jul  7 03:16:22 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKGrXGPSGrLz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "835cd182-82ee-4f30-f5b8-f6db8bdd00fb"
      },
      "source": [
        "!pip install stemming"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stemming\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/eb/fd53fb51b83a4e3b8e98cfec2fa9e4b99401fce5177ec346e4a5c61df71e/stemming-1.0.1.tar.gz\n",
            "Building wheels for collected packages: stemming\n",
            "  Building wheel for stemming (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stemming: filename=stemming-1.0.1-cp36-none-any.whl size=11139 sha256=5cc968535c06561243a12d8e48a97652d9a317f651cd3f7e5cbbc0b897298ff7\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/05/2e/2ddeb64d4464b854b48323f9676528c17560da7d153db7b0e2\n",
            "Successfully built stemming\n",
            "Installing collected packages: stemming\n",
            "Successfully installed stemming-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd7HS2eIEXYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "from stemming.porter2 import stem\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVp2-bdHP5xD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.nn.utils.rnn as rnn\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gByKXsH_yJw",
        "colab_type": "text"
      },
      "source": [
        "## 80. ID番号への変換\n",
        "問題51で構築した学習データ中の単語にユニークなID番号を付与したい．学習データ中で最も頻出する単語に1，2番目に頻出する単語に2，……といった方法で，学習データ中で2回以上出現する単語にID番号を付与せよ．そして，与えられた単語列に対して，ID番号の列を返す関数を実装せよ．ただし，出現頻度が2回未満の単語のID番号はすべて0とせよ．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bimMAXQTEOZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0zopvj-EvDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"./drive/My Drive/Colab Notebooks/data/NewsAggregatorDataset/newsCorpora.csv\", \"r\") as intxt:\n",
        "    inline = intxt.readlines()\n",
        "    \n",
        "select_publisher = [\"Reuters\", \"Huffington Post\", \"Businessweek\", \"Contactmusic.com\", \"Daily Mail\"]\n",
        "datas = []\n",
        "\n",
        "for line in inline:\n",
        "    if line != \"\":\n",
        "        ll = line.split(\"\\t\")\n",
        "        if ll[3] in select_publisher:\n",
        "            datas.append((ll[4],ll[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qh8wKWLRFsaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_feat_from_sentence(string):\n",
        "    sl = nlp.make_doc(string)\n",
        "    string = [i.lemma_.lower() for i in sl]\n",
        "    return string\n",
        "\n",
        "def data2stemmed(data):\n",
        "    return [(label, get_feat_from_sentence(string)) for label,string in data]\n",
        "\n",
        "def get_feature_stems(stemmed):\n",
        "    counter = Counter([tok for _,toks in stemmed for tok in toks])\n",
        "    return [stem for stem,num in counter.most_common() if 2<=num]\n",
        "\n",
        "def make_feature_dic(features):\n",
        "    dic = {}\n",
        "    for i, word in enumerate(features):\n",
        "        dic[word] = i+1\n",
        "    return dic\n",
        "\n",
        "def get_id(stemmed, feature_dic):\n",
        "    if stemmed in feature_dic:\n",
        "        return feature_dic[stemmed]\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def get_ids(stemmedl, feature_dic):\n",
        "    return [get_id(i, feature_dic) for i in stemmedl]\n",
        "\n",
        "def stemmed2ids(stemmed, feature_dic):\n",
        "    return [(label, get_ids(steml, feature_dic)) for label,steml in stemmed]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFiFjAneFtHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stemmed = data2stemmed(datas)\n",
        "features = get_feature_stems(stemmed)\n",
        "feature_dic = make_feature_dic(features)\n",
        "ids = stemmed2ids(stemmed, feature_dic)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Uhxkhnbq9MM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "929fe171-f6d1-442c-ba1a-923796e7898f"
      },
      "source": [
        "len(features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8600"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apwg79L3JwMZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "32f23e15-bed1-48d1-9efb-c198c398a15c"
      },
      "source": [
        "print(get_id(\"-\", feature_dic))\n",
        "print(get_id(\"hogehoge\", feature_dic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcXaXqoSKgR2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f65b8147-5973-4310-a9e4-ebb1543afc6a"
      },
      "source": [
        "stemmed[0][1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['europe', 'reach', 'crunch', 'point', 'on', 'bank', 'union']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26nuFOogKoRE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "83710a36-8d75-43c1-a7c3-000348dfc15e"
      },
      "source": [
        "get_ids(stemmed[0][1], feature_dic)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[247, 858, 0, 927, 13, 60, 957]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsLDIxNaLVlw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d23ff200-0f4b-4b87-809e-287a4b8e4ee2"
      },
      "source": [
        "for i in ids[:3]:\n",
        "   print(i)\n",
        "\n",
        "for i in ids[-3:]:\n",
        "   print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('b', [247, 858, 0, 927, 13, 60, 957])\n",
            "('b', [54, 604, 1, 2586, 43, 0, 61, 54, 5, 1249, 3, 419, 72, 45, 12, 7, 6])\n",
            "('b', [43, 0, 0, 9, 6314, 116, 550, 4, 1900, 243, 4220])\n",
            "('m', [14, 0, 1611, 116, 8600, 4, 669, 1737, 1, 126])\n",
            "('m', [246, 1301, 49, 0, 4943, 4, 126, 65, 8, 4975, 158])\n",
            "('m', [337, 707, 1692, 745, 3, 246, 1, 104, 2123, 2124, 20, 2898, 11, 464, 7, 6])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1aGamoNQgEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ids2ids_onehot(ids, features):\n",
        "    size = len(features) + 1\n",
        "    identity = np.identity(size)\n",
        "    return [(label, identity[i]) for label,i in tqdm(ids)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SXQi-4VRU1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ids_onehot = ids2ids_onehot(ids, features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15W-KXrIZ-BT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for i in ids_onehot[:3]:\n",
        "#   print(i)\n",
        "\n",
        "#for i in ids_onehot[-3:]:\n",
        "#   print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wX40EirAAJw",
        "colab_type": "text"
      },
      "source": [
        "## 81. RNNによる予測"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COu4zhS2S-PR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#random.shuffle(ids_onehot)\n",
        "random.shuffle(ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0NW3WD5qILC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model81(nn.Module):\n",
        "    def __init__(self, input_dim, embed_dim, hidden_dim, out_dim):\n",
        "        super(Model81, self).__init__()\n",
        "        self.embed = nn.Embedding(input_dim, embed_dim)\n",
        "        self.rnn = nn.RNN(embed_dim, hidden_dim, num_layers=1, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_dim, out_dim)\n",
        "        nn.init.normal_(self.embed.weight, 0.0, 1.0)\n",
        "        #self.loss = nn.CrossEntropyLoss()\n",
        "    \n",
        "    def predict(self, x, h=None):\n",
        "        x = self.embed(x.to(torch.int64))\n",
        "        x, hp = self.rnn(x, h)\n",
        "        h = self.out(hp)\n",
        "        #print(h)\n",
        "        h = h.squeeze(0)\n",
        "        return h\n",
        "\n",
        "    def forward(self, x):\n",
        "        label = self.predict(x, None)\n",
        "        #return self.loss(label, ans)\n",
        "        return label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OxWAqpVqwRl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model81(8601, 300, 50, 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jZfbrYyuc2N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f7c797c6-cc1e-49df-f770-8fbd219f76b2"
      },
      "source": [
        "print(model.predict(torch.tensor(ids[0][1]).unsqueeze(0)))\n",
        "print(ids[0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.0944, -0.3514, -0.1393, -0.9557]], grad_fn=<SqueezeBackward1>)\n",
            "e\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzOK3maLAN2R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0dfda8e2-46cb-449b-e0fa-e18b4ae176d7"
      },
      "source": [
        "print(model.predict(torch.tensor(ids[1][1]).unsqueeze(0)))\n",
        "print(ids[1][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.3029, -0.3453, -0.9609,  0.1288]], grad_fn=<SqueezeBackward1>)\n",
            "t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbH_6XPMAFfG",
        "colab_type": "text"
      },
      "source": [
        "## 82. 確率的勾配降下法による学習"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcqDdSTmJuHY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4cbc9742-272c-448f-e89c-b38626f48d69"
      },
      "source": [
        "label_dic = {\"b\":0, \"e\":1, \"m\":2, \"t\":3}\n",
        "\n",
        "def div_vecs(vecs):\n",
        "    x = [np.array(i[1]) for i in vecs]\n",
        "    label = [label_dic[i[0]] for i in vecs]\n",
        "    return x,label\n",
        "\n",
        "trains = ids[:len(ids)*4//5]\n",
        "print(\"train data :\",len(trains))\n",
        "\n",
        "tests = ids[len(ids)*8//10:len(ids)*9//10]\n",
        "print(\"valid data :\",len(tests))\n",
        "\n",
        "valids = ids[len(ids)*9//10:]\n",
        "print(\"test data :\",len(valids))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train data : 10684\n",
            "valid data : 1336\n",
            "test data : 1336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dK0yRMbdKOPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainx, trainy = div_vecs(trains)\n",
        "testx, testy = div_vecs(tests)\n",
        "validx, validy = div_vecs(valids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lHSunHZKTf2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datasets = [trainx, trainy, testx, testy, validx, validy]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzYx3nXWc-vg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def try_gpu(e):\n",
        "    if torch.cuda.is_available():\n",
        "        return e.cuda()\n",
        "    return e"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGOTSift3nCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model81(nn.Module):\n",
        "    def __init__(self, input_dim, embed_dim, hidden_dim, out_dim):\n",
        "        super(Model81, self).__init__()\n",
        "        self.embed = nn.Embedding(input_dim, embed_dim)\n",
        "        self.rnn = nn.RNN(embed_dim, hidden_dim, num_layers=1, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_dim, out_dim)\n",
        "        nn.init.normal_(self.embed.weight, 0.0, 1.0)\n",
        "    \n",
        "    def predict(self, x, h=None):\n",
        "        x = self.forward(x, h)\n",
        "        x = F.softmax(x, dim=1)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x, h=None):\n",
        "        x = self.embed(x.to(torch.int64))\n",
        "        x, hp = self.rnn(x, h)\n",
        "        h = self.out(hp)\n",
        "        #print(h)\n",
        "        h = h.squeeze(0)\n",
        "        return h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fkrv6Fi85uT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset, status, use_gpu=False):\n",
        "        dic = {\"train\":0, \"test\":1, \"valid\":2}\n",
        "        self.status = status\n",
        "        vecs = dataset\n",
        "        self.data = vecs[dic[status]*2]\n",
        "        self.label = vecs[dic[status]*2+1]\n",
        "        self.data_num = len(self.data)\n",
        "        self.use_gpu = use_gpu\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.data_num\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        out_data = self.data[idx]\n",
        "        out_label =  self.label[idx]\n",
        "        return out_data, out_label\n",
        "    \n",
        "    def collate(self, batch):\n",
        "        datas, labels = list(zip(*batch))\n",
        "        datas = [torch.tensor(data) for data in datas]\n",
        "        datas = pad_sequence(datas, batch_first=True)\n",
        "        if self.use_gpu:\n",
        "            return try_gpu(datas), try_gpu(torch.tensor(labels))\n",
        "        else:\n",
        "            return datas, torch.tensor(labels)\n",
        "\n",
        "def generator(dataset, status, batch_size, shuffle=True, use_gpu=False):\n",
        "    data_set = Dataset(dataset, status, use_gpu)\n",
        "    return torch.utils.data.DataLoader(data_set, collate_fn = data_set.collate, batch_size=batch_size, shuffle=shuffle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm7yDRhr54vb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ab5b1360-e77e-4c4d-cb8f-eb0e524d2a39"
      },
      "source": [
        "ds = generator(datasets, \"train\", 1)\n",
        "for x, y in ds:\n",
        "  print(x,y)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 699, 1041,    3,  521,   15, 8050, 4370, 5606, 4414,   20, 1827,  521,\n",
            "         1414,    7,    6]]) tensor([3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJZDZ6CmMN1h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e0b10109-0c7d-4e12-e57b-67fd758af848"
      },
      "source": [
        "ds = generator(datasets, \"train\", 100)\n",
        "for x, y in ds:\n",
        "  print(x,y)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[  14,    0, 5257,  ...,    0,    0,    0],\n",
            "        [ 340,  797, 1296,  ...,    0,    0,    0],\n",
            "        [  17,   33,    1,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [2057,   11,  926,  ...,    0,    0,    0],\n",
            "        [3953,   11,  861,  ...,    0,    0,    0],\n",
            "        [1175, 4044, 1262,  ...,    0,    0,    0]]) tensor([0, 1, 0, 3, 0, 1, 2, 0, 0, 3, 0, 1, 1, 2, 1, 1, 1, 0, 2, 1, 3, 0, 1, 1,\n",
            "        0, 0, 2, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
            "        0, 2, 3, 1, 3, 0, 0, 1, 0, 0, 1, 1, 0, 0, 3, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
            "        0, 2, 0, 1, 3, 0, 2, 3, 1, 3, 0, 0, 0, 1, 2, 1, 0, 1, 3, 1, 3, 1, 0, 1,\n",
            "        1, 1, 0, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gj8jiOkYXAMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(dataset, md, use_gpu=False):\n",
        "    with torch.no_grad():\n",
        "        if use_gpu:\n",
        "            predicts = [md.predict(try_gpu(torch.tensor(dat).unsqueeze(0))) for dat in dataset.data]\n",
        "        else:\n",
        "            predicts = [md.predict(torch.tensor(dat).unsqueeze(0)) for dat in dataset.data]\n",
        "        return np.mean([int(p.argmax()==a) for p,a in zip(predicts, dataset.label)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKDrDvIy42TB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## batch>=2のときスコアが明らかに悪い(パディングがヤバそう)　要改善\n",
        "class TRAINER:\n",
        "    def __init__(self, model, criterion, vecs, optimizer, gen_batchsize, max_iter, use_gpu=False):\n",
        "        self.train_generator = generator(datasets, \"train\", gen_batchsize, True,  use_gpu)\n",
        "        self.valid_generator = generator(datasets, \"valid\", 1, True, use_gpu)\n",
        "        self.train_dataset = Dataset(datasets, \"train\")\n",
        "        self.valid_dataset = Dataset(datasets, \"valid\")\n",
        "        self.model = model\n",
        "        if use_gpu:\n",
        "            self.model = try_gpu(self.model)\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.max_iter = max_iter\n",
        "        self.use_gpu = use_gpu\n",
        "\n",
        "    def train(self):\n",
        "        self.model.train()\n",
        "        train_losses = []\n",
        "        for x,y in self.train_generator:\n",
        "            out = self.model(x)\n",
        "            loss = self.criterion(out, y)\n",
        "            #self.optimizer.zero_grad()\n",
        "            self.model.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            train_losses.append(loss.item())\n",
        "        return accuracy(self.train_dataset, model, self.use_gpu), np.mean(train_losses)\n",
        "        \n",
        "    def valid(self):\n",
        "        self.model.eval()\n",
        "        valid_losses = []\n",
        "        for x, y in self.valid_generator:\n",
        "            with torch.no_grad():\n",
        "                out = self.model(x)\n",
        "                loss = self.criterion(out, y)\n",
        "                valid_losses.append(loss.item())\n",
        "        return accuracy(self.valid_dataset, model, self.use_gpu), np.mean(valid_losses)\n",
        "\n",
        "    def learning(self):\n",
        "        for ep in range(self.max_iter):\n",
        "            train_acc, train_loss = self.train()\n",
        "            valid_acc, valid_loss = self.valid()\n",
        "            print(train_acc, valid_acc, train_loss, valid_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aoCr2A66iWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model81(8601, 300, 50, 4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "trainer = TRAINER(model, criterion, datasets, optimizer, 1, 5, False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhkIExaFZad5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b98df97-2200-4e14-e5a8-0958e36896db"
      },
      "source": [
        "train_dataset = Dataset(datasets, \"train\")\n",
        "accuracy(train_dataset, model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.293803818794459"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a98y_yMAjOLB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "ab01295f-9419-421e-b950-524c08632ac1"
      },
      "source": [
        "print(\"train_accuracy / valid_accuracy / train_loss / valid_loss\")\n",
        "trainer.learning()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_accuracy / valid_accuracy / train_loss / valid_loss\n",
            "0.7308124298015725 0.7073353293413174 0.9822527083602446 0.8684948053445198\n",
            "0.7687195806813928 0.7215568862275449 0.789449693042046 0.8144324706312448\n",
            "0.7876263571695994 0.7395209580838323 0.6887827925964378 0.7597779967110397\n",
            "0.8177648820666417 0.7402694610778443 0.622257382522957 0.7541777664369591\n",
            "0.8306813927368027 0.7657185628742516 0.562488233715828 0.7783636722402542\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WomFkyUDAIae",
        "colab_type": "text"
      },
      "source": [
        "## 83. ミニバッチ化・GPU上での学習"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnEWx5v2c6yR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4db529c7-3444-4686-dd8a-dd507a1cbb2a"
      },
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Y_mxr1ZjvOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model81(8601, 300, 50, 4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "trainer = TRAINER(model, criterion, datasets, optimizer, 4, 10, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NGNNswgjyAT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e90ed1c9-8340-4d46-f28c-1d22d3eef10a"
      },
      "source": [
        "print(\"train_accuracy / valid_accuracy / train_loss / valid_loss\")\n",
        "trainer.learning()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_accuracy / valid_accuracy / train_loss / valid_loss\n",
            "0.5446461999251216 0.5486526946107785 1.1458693519932015 1.1041750812869586\n",
            "0.5768438786971172 0.5688622754491018 1.1166642746622757 1.0642547464656258\n",
            "0.6219580681392737 0.5988023952095808 1.0890664964613064 1.028139219357225\n",
            "0.6846686634219393 0.6788922155688623 1.0135935698274994 0.934703773411805\n",
            "0.7100336952452265 0.7013473053892215 0.9585364049336117 0.8930339098512056\n",
            "0.7031074503931112 0.6893712574850299 1.0081992586959574 0.9004446455461537\n",
            "0.5862036690378135 0.5845808383233533 0.9665696329389427 1.0785217452905849\n",
            "0.662392362411082 0.6482035928143712 1.07155192914816 0.9705307362768465\n",
            "0.7057281916885062 0.686377245508982 0.9830898343568346 0.9182277883508962\n",
            "0.7141520029951329 0.6953592814371258 0.9444791389143186 0.9010971833667355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LwQ-av8AJtf",
        "colab_type": "text"
      },
      "source": [
        "## 84. 単語ベクトルの導入"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okMoqFZid54f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "49eef2d9-898e-4856-a958-29aaaa02dc87"
      },
      "source": [
        "import gensim\n",
        "googlenews_w2v = gensim.models.KeyedVectors.load_word2vec_format('./drive/My Drive/Colab Notebooks/data/GoogleNews-vectors-negative300.bin', binary=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxE2SUAWhLJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "def init_emb_w2v(model):\n",
        "    for i, token in enumerate(features):\n",
        "        if token in googlenews_w2v:\n",
        "            vc = copy.deepcopy(googlenews_w2v[token])\n",
        "            model.embed.weight.data[i] = torch.tensor(vc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfjTPDT1qZMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model81(8601, 300, 50, 4)\n",
        "init_emb_w2v(model)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "trainer = TRAINER(model, criterion, datasets, optimizer, 1, 5, False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RNp4TQIq9XG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "379f6721-0df2-4ecd-8625-f6af38bb433b"
      },
      "source": [
        "print(\"train_accuracy / valid_accuracy / train_loss / valid_loss\")\n",
        "trainer.learning()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_accuracy / valid_accuracy / train_loss / valid_loss\n",
            "0.652096593036316 0.6317365269461078 1.0577447965569606 0.9893915286666887\n",
            "0.7288468738300262 0.7148203592814372 0.9263852405404022 0.8395172570773517\n",
            "0.7658180456757768 0.718562874251497 0.7914477826974092 0.8162118859427373\n",
            "0.7821976787719955 0.7485029940119761 0.6981621248252222 0.8251152227174011\n",
            "0.8110258330213403 0.7350299401197605 0.6243131635911742 0.7703471740921765\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lME6quBEAMvM",
        "colab_type": "text"
      },
      "source": [
        "## 85. 双方向RNN・多層化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evoSmV2mtK5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model85(nn.Module):\n",
        "    def __init__(self, input_dim, embed_dim, hidden_dim, out_dim):\n",
        "        super(Model85, self).__init__()\n",
        "        self.embed = nn.Embedding(input_dim, embed_dim)\n",
        "        self.rnn = nn.RNN(embed_dim, hidden_dim, num_layers=2, batch_first=True, bidirectional=True)\n",
        "        self.out = nn.Linear(hidden_dim*2, out_dim)\n",
        "        nn.init.normal_(self.embed.weight, 0.0, 1.0)\n",
        "    \n",
        "    def predict(self, x, h=None):\n",
        "        x = self.forward(x, h)\n",
        "        x = F.softmax(x, dim=1)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x, h=None):\n",
        "        x = self.embed(x.to(torch.int64))\n",
        "        x, hp = self.rnn(x, h)\n",
        "        h = hp[-2:]\n",
        "        h = h.transpose(0,1)\n",
        "        h = h.contiguous().view(-1, h.size(1) * h.size(2))\n",
        "        h = self.out(h)\n",
        "        return h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRmIXSU-gSNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model85(8601, 300, 50, 4)\n",
        "init_emb_w2v(model)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "trainer = TRAINER(model, criterion, datasets, optimizer, 1, 5, False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSE7OSFUgWfu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "ac60487c-7c1f-4d1b-e7b3-4add30227e79"
      },
      "source": [
        "print(\"train_accuracy / valid_accuracy / train_loss / valid_loss\")\n",
        "trainer.learning()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_accuracy / valid_accuracy / train_loss / valid_loss\n",
            "0.7704043429427181 0.7402694610778443 0.8718260271098233 0.745074547161167\n",
            "0.8592287532759266 0.7859281437125748 0.6132917340548394 0.6117972818947945\n",
            "0.8887120928491202 0.8023952095808383 0.4511631824753068 0.579840137231438\n",
            "0.9239985024335455 0.8270958083832335 0.32984242661446256 0.5580287224444443\n",
            "0.9541370273305878 0.8353293413173652 0.2435087069509945 0.5792550135639964\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKzalUjptlFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model85(8601, 300, 50, 4)\n",
        "init_emb_w2v(model)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.02)\n",
        "trainer = TRAINER(model, criterion, datasets, optimizer, 8, 10, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slsPPL2fvclK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9ead40dc-674d-425b-b483-cc80ff8d6228"
      },
      "source": [
        "print(\"train_accuracy / valid_accuracy / train_loss / valid_loss\")\n",
        "trainer.learning()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_accuracy / valid_accuracy / train_loss / valid_loss\n",
            "0.6099775365031823 0.592814371257485 0.9679292242550207 1.070125158229274\n",
            "0.7585174092100337 0.7447604790419161 0.7881251931368948 0.7404168622936317\n",
            "0.7746162485960314 0.7335329341317365 0.677808401001963 0.7321860723777446\n",
            "0.8230063646574317 0.7747005988023952 0.5849296065984283 0.6266814275772986\n",
            "0.7677836016473231 0.7170658682634731 0.5088952729913467 0.7930596894668248\n",
            "0.8708348932983901 0.8023952095808383 0.4452917826456759 0.5594385755276252\n",
            "0.8837514039685511 0.8046407185628742 0.3801768596289668 0.5803251109437314\n",
            "0.9116435791838263 0.8151197604790419 0.3275278561419534 0.5589102379040803\n",
            "0.9182890303257207 0.8143712574850299 0.27757048916383953 0.6037391513407587\n",
            "0.9412205166604268 0.8173652694610778 0.23550863502669833 0.5867536088039061\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReYIs73wAPKz",
        "colab_type": "text"
      },
      "source": [
        "## 86. 畳み込みニューラルネットワーク (CNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i2N5o7JSlWe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model86(nn.Module):\n",
        "    def __init__(self, input_dim, embed_dim, hidden_dim, out_dim):\n",
        "        super(Model86, self).__init__()\n",
        "        self.embed = nn.Embedding(input_dim, embed_dim)\n",
        "        self.conv = nn.Conv1d(embed_dim, hidden_dim, kernel_size=3, padding=1)\n",
        "        self.act = nn.ReLU()\n",
        "        self.pool = nn.MaxPool1d(kernel_size=3)\n",
        "        self.out = nn.Linear(hidden_dim, out_dim)\n",
        "        nn.init.normal_(self.embed.weight, 0.0, 1.0)\n",
        "    \n",
        "    def predict(self, x):\n",
        "        x = self.forward(x)\n",
        "        x = F.softmax(x, dim=1)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embed(x.to(torch.int64))\n",
        "        x = self.conv(x.transpose(-1,-2))\n",
        "        x = self.act(x)\n",
        "        x = F.max_pool1d(x, x.size(-1))\n",
        "        x = x.squeeze(-1)\n",
        "        x = self.out(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2k6Gf7jV2vAS",
        "colab_type": "text"
      },
      "source": [
        "## 87. 確率的勾配降下法によるCNNの学習"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vqx-LadLSqJC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model86(8601, 300, 50, 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe71QPImStfq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6f61542a-1e35-4aff-c5d1-7a9184fbb3b0"
      },
      "source": [
        "print(model.predict(torch.tensor(ids[0][1]).unsqueeze(0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0877, 0.2863, 0.3967, 0.2292]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyHm3GEkgnBj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model86(8601, 300, 50, 4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "trainer = TRAINER(model, criterion, datasets, optimizer, 1, 5, False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrVtBSPPocBE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "4af9719a-9074-425e-ff26-0eb18b7dc067"
      },
      "source": [
        "print(\"train_accuracy / valid_accuracy / train_loss / valid_loss\")\n",
        "trainer.learning()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_accuracy / valid_accuracy / train_loss / valid_loss\n",
            "0.752807937102209 0.7155688622754491 1.457637474694676 3.0803044119107206\n",
            "0.6767128416323475 0.6422155688622755 6.809485087754355 11.905877648207417\n",
            "0.8400411830774991 0.7664670658682635 11.68659215040173 13.791731543565318\n",
            "0.8862785473605391 0.7739520958083832 8.354457061628628 16.8977603638319\n",
            "0.9288655934107076 0.8106287425149701 5.021623709647513 14.891164257820476\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}